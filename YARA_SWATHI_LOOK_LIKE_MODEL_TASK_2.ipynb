{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK - 2 LOOK A LIKE MODEL**"
      ],
      "metadata": {
        "id": "a6jXEBHhjbq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "NkA4EJjsjltr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Datasets\n",
        "Customers = pd.read_csv('/content/Customers.csv')\n",
        "Products = pd.read_csv('/content/Products.csv')\n",
        "Transactions = pd.read_csv('/content/Transactions.csv')"
      ],
      "metadata": {
        "id": "Prn6OXRvj155"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse date columns\n",
        "Customers['SignupDate'] = pd.to_datetime(Customers['SignupDate'])\n",
        "Transactions['TransactionDate'] = pd.to_datetime(Transactions['TransactionDate'])"
      ],
      "metadata": {
        "id": "dJvz2nIKj-kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge datasets\n",
        "data = pd.merge(Transactions, Customers, on='CustomerID')\n",
        "data = pd.merge(data, Products, on='ProductID')"
      ],
      "metadata": {
        "id": "_fiCffqikHWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate transaction data for customers\n",
        "# Merge 'Price' column from Products DataFrame to data DataFrame\n",
        "data = pd.merge(data, Products[['ProductID', 'Price']], on='ProductID', how='left')\n",
        "\n",
        "Customer_features = data.groupby('CustomerID').agg({\n",
        "    'TotalValue': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'Price': 'mean'  # Now 'Price' column is available\n",
        "}).reset_index()"
      ],
      "metadata": {
        "id": "9wjwBobukLea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge with customer profile\n",
        "Customer_profiles = pd.merge(Customers, Customer_features, on='CustomerID')"
      ],
      "metadata": {
        "id": "sn4OXkmykPnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical data (e.g., Region)\n",
        "Customer_profiles = pd.get_dummies(Customer_profiles, columns=['Region'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "DvEvIWSGkTNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize features, excluding the 'SignupDate' column\n",
        "features_to_scale = Customer_profiles.select_dtypes(include=np.number) # Select only numeric columns\n",
        "\n",
        "# Check if 'CustomerID' is in the columns before dropping it\n",
        "if 'CustomerID' in features_to_scale.columns:\n",
        "    features_to_scale = features_to_scale.drop(columns=['CustomerID']) # Exclude 'CustomerID' if it exists\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features_to_scale)\n",
        "\n",
        "# Create a new DataFrame with scaled features and original 'CustomerID' and 'SignupDate'\n",
        "Customer_profiles_scaled = pd.DataFrame(features_scaled, columns=features_to_scale.columns, index=Customer_profiles.index)\n",
        "Customer_profiles_scaled[['CustomerID', 'SignupDate']] = Customer_profiles[['CustomerID', 'SignupDate']]"
      ],
      "metadata": {
        "id": "qQ8tT-zlkYIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute similarity matrix\n",
        "similarity_matrix = cosine_similarity(features_scaled)\n"
      ],
      "metadata": {
        "id": "wcPm8VR8kbe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map each customer ID to their top 3 similar customers\n",
        "lookalike_dict = {}\n",
        "Customer_ids = Customer_profiles['CustomerID']\n",
        "\n",
        "for i, customer_id in enumerate(Customer_ids[:20]):  # First 20 customers\n",
        "    # Get similarity scores for the current customer\n",
        "    similarity_scores = list(enumerate(similarity_matrix[i]))\n",
        "    # Sort by similarity score in descending order (excluding the customer itself)\n",
        "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)[1:4]\n",
        "    # Map customer ID to the top 3 similar customers\n",
        "    lookalike_dict[customer_id] = [(Customer_ids[j], round(score, 2)) for j, score in similarity_scores]\n"
      ],
      "metadata": {
        "id": "yXmtMghGkepm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert lookalike dictionary to DataFrame and save to CSV\n",
        "lookalike_df = pd.DataFrame([\n",
        "    {'CustomerID': cust_id, 'Lookalikes': str(lookalikes)}\n",
        "    for cust_id, lookalikes in lookalike_dict.items()\n",
        "])\n",
        "\n",
        "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
        "\n",
        "# Display the generated lookalike file for verification\n",
        "print(lookalike_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds69z1-MkiQC",
        "outputId": "e1bd4049-6e18-4fbc-fae3-3447f8f5cbca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   CustomerID                                         Lookalikes\n",
            "0       C0001  [('C0103', 1.0), ('C0092', 1.0), ('C0135', 0.99)]\n",
            "1       C0002   [('C0029', 1.0), ('C0077', 1.0), ('C0157', 1.0)]\n",
            "2       C0003  [('C0111', 1.0), ('C0190', 1.0), ('C0038', 0.99)]\n",
            "3       C0004   [('C0165', 1.0), ('C0162', 1.0), ('C0075', 1.0)]\n",
            "4       C0005   [('C0167', 1.0), ('C0020', 1.0), ('C0128', 1.0)]\n",
            "5       C0006  [('C0168', 1.0), ('C0196', 1.0), ('C0187', 0.99)]\n",
            "6       C0007   [('C0125', 1.0), ('C0089', 1.0), ('C0085', 1.0)]\n",
            "7       C0008  [('C0084', 1.0), ('C0113', 1.0), ('C0017', 0.99)]\n",
            "8       C0009   [('C0130', 1.0), ('C0128', 1.0), ('C0192', 1.0)]\n",
            "9       C0010  [('C0176', 1.0), ('C0055', 0.99), ('C0174', 0....\n",
            "10      C0011  [('C0023', 1.0), ('C0139', 0.99), ('C0100', 0....\n",
            "11      C0012   [('C0101', 1.0), ('C0093', 1.0), ('C0153', 1.0)]\n",
            "12      C0013   [('C0021', 1.0), ('C0141', 1.0), ('C0059', 1.0)]\n",
            "13      C0014   [('C0097', 1.0), ('C0043', 1.0), ('C0032', 1.0)]\n",
            "14      C0015  [('C0058', 1.0), ('C0186', 0.99), ('C0131', 0....\n",
            "15      C0016   [('C0040', 1.0), ('C0107', 1.0), ('C0066', 1.0)]\n",
            "16      C0017  [('C0113', 1.0), ('C0084', 0.99), ('C0008', 0....\n",
            "17      C0018  [('C0041', 0.99), ('C0068', 0.99), ('C0004', 0...\n",
            "18      C0019  [('C0166', 1.0), ('C0031', 0.99), ('C0088', 0....\n",
            "19      C0020   [('C0005', 1.0), ('C0128', 1.0), ('C0167', 1.0)]\n"
          ]
        }
      ]
    }
  ]
}